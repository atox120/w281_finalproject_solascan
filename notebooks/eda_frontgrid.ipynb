{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167aa27-00d8-4bb9-8018-216d9796120e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1831ff-8aa2-4ce7-bc8e-a2b7c567d280",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import tabulate\n",
    "import numpy as np\n",
    "sys.path.append(os.path.join(os.path.abspath(\"\"), \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0c3332-e7d2-47c6-934a-bbbaf14f4724",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from app.models import Classifier\n",
    "from app.utils import ImageWrapper \n",
    "from app.transforms import FFT, IFFT, CreateOnesMask\n",
    "from app.filters import CreateKernel, Convolve, Canny, HOG\n",
    "from app.imager import ImageLoader, DefectViewer, Show, Exposure\n",
    "from app.custom import RemoveBusBars, Orient, HighlightFrontGrid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67926450-eae9-40e5-bfdd-19b884699281",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Seed used in show to show the same images when num_images option is set\n",
    "seed = 1234\n",
    "scores = []\n",
    "legends = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f10d0ff-0064-44d9-8c29-07d1fe5b7ffe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Analyzing which defect \n",
    "n_samples = 2000\n",
    "defect_class = ['FrontGridInterruption', 'NearSolderPad']\n",
    "compliment = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2bf236",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load 10 examples and name the category for it. Category is like a title for images\n",
    "defect_class = defect_class\n",
    "defect = (DefectViewer(row_chop=15, col_chop=15) << (ImageLoader(defect_class=defect_class) << n_samples))\n",
    "defect.category = 'GridInterruption'\n",
    "\n",
    "# Make the other teh same length as the defect\n",
    "num_samples = len(defect)\n",
    "\n",
    "# Get the not this defect\n",
    "# not_defect = (DefectViewer(row_chop=15, col_chop=15) << (ImageLoader(defect_class='FrontGridInterruption', is_not=True) << n_samples))\n",
    "if not compliment:\n",
    "    not_defect = (DefectViewer(row_chop=15, col_chop=15) << (ImageLoader(defect_class='None', is_not=False) << n_samples*2))\n",
    "    not_defect.category = 'No defects'\n",
    "else:\n",
    "    not_defect = (DefectViewer(row_chop=15, col_chop=15) << (ImageLoader(defect_class=defect_class, is_not=True) << n_samples*2))\n",
    "    not_defect.category = 'Other'\n",
    "\n",
    "# Create a copy of the defect\n",
    "defect_ = defect.copy()\n",
    "\n",
    "# Eliminate any not defect images that are in defect\n",
    "defect = defect - not_defect\n",
    "\n",
    "# ELiminate any defect images that are in not defect\n",
    "not_defect = not_defect - defect_\n",
    "\n",
    "# View both the defect and the clean class\n",
    "# I am using a tuple in this case as defect and clean are ImageWrapper objects\n",
    "# Show random 5 out of the 10 images. Using the seed will ensure the same 5 are shown everytime\n",
    "_ = Show(num_images=2, seed=seed) << (defect, not_defect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958c82c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(defect))\n",
    "print(len(not_defect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33434f26-9ce9-4533-992c-a7172f94d770",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Base model on raw data\n",
    "model_params = {'penalty': 'l2', 'seed': 14376, 'pca_dims': None}\n",
    "cla = Classifier(defect, not_defect, LogisticRegression, None)\n",
    "score = cla.fit_cv(**model_params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append('Baseline Logistic Regression model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c134a-2582-486f-b086-c4c45799925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Base model on raw data with pca\n",
    "pca_dims = 800\n",
    "model_params = {'penalty': 'l2', 'seed': 14376, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect, not_defect, LogisticRegression, None)\n",
    "score = cla.fit_cv(**model_params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Logitc regression with {pca_dims} dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1bd7e8-82da-4608-bcbb-edda0d536c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Gradient Boosted Classifier \n",
    "pca_dims = 200\n",
    "params = {'seed': 14376,'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect, not_defect, GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit_cv(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Gradient Boosted Classifier model with {pca_dims} dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cfe407-ff6e-4e1f-afa1-cd9592a82715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the oriented images and HOG\n",
    "start = time.perf_counter()\n",
    "oriented_defect = Orient(num_jobs=20, do_debug=True, do_eliminate=False) << defect\n",
    "oriented_not_defect = Orient(num_jobs=20, do_debug=True, do_eliminate=False) << not_defect\n",
    "print(time.perf_counter() - start)\n",
    "\n",
    "# View both the defect and the clean class\n",
    "# I am using + operator as oriented_defect and oriented_clean are tuples\n",
    "_ = Show(num_images=10, seed=seed) << oriented_defect + oriented_not_defect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e3545-fd79-4888-8699-3ff6634fe21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Sobel features\n",
    "defect_kernel = CreateKernel(kernel='sobel', axis=0) << oriented_defect\n",
    "not_defect_kernel = CreateKernel(kernel='sobel', axis=0) << oriented_not_defect\n",
    "\n",
    "sobel_defect = Convolve() << defect_kernel\n",
    "sobel_not_defect = Convolve() << not_defect_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bec21-0e8f-4488-bca2-646aabca8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_ = oriented_defect[-1] & sobel_defect[-1]\n",
    "not_defect_ = oriented_not_defect[-1] & sobel_not_defect[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a533ada-753e-4175-a58f-fce4cb87a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient booster with PCA features\n",
    "pca_dims = 100\n",
    "params = {'seed': 14376,'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect_ , not_defect_, GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit_cv(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Gradient Boosted Classifier model with {pca_dims} dimensions and Sobel images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7fd5b7-cd0a-4b18-be51-b88f2804e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.models import ModelNN\n",
    "\n",
    "lr = 0.00005\n",
    "pca_dims = 1000\n",
    "if pca_dims is None:\n",
    "    dense_layers = (2000, 1000, 300, 300, 300)\n",
    "else:\n",
    "    dense_layers = (pca_dims, int(pca_dims/2), int(pca_dims/2), int(pca_dims/2), int(pca_dims/2))\n",
    "\n",
    "optimizer_params = {'name': 'sgd', 'lr': lr, 'nesterov': False, 'momentum': 0.9}\n",
    "scheduler_params = {'lr_min': lr/100, 't_mul': 2}\n",
    "model_params = {'num_output_classes': 2, 'dense_layers': (2000, 1000, 300, 300, 300), 'dense_activation': 'relu', \n",
    "                'pca_dims': pca_dims, 'dropout': 0.2}\n",
    "\n",
    "# model = ModelNN(defect, not_defect, model_params, optimizer_params, scheduler_params, model_type='dnn')\n",
    "model = ModelNN(defect_, not_defect_, model_params, optimizer_params, scheduler_params, model_type='dnn')\n",
    "score = model.fit(num_epochs=30)\n",
    "\n",
    "print(score)\n",
    "scores.append(score)\n",
    "legends.append(f'DNN with {pca_dims} dims on enhanced images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d7058-a108-4b57-b1bf-bb41570b7db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.models import ModelNN\n",
    "\n",
    "lr = 0.0001\n",
    "optimizer_params = {'name': 'sgd', 'lr': lr, 'nesterov': True, 'momentum': 0.9}\n",
    "scheduler_params = {'lr_min': lr/100, 't_mul': 3}\n",
    "model_params = {'num_output_classes': 2, 'channels': ((1, 5), (10, 3), (10, 3), (10, 3), (10, 3)), 'dense_layers': (1000, 500, 500)}\n",
    "\n",
    "model = ModelNN(oriented_defect[-1], oriented_not_defect[-1], model_params, optimizer_params, scheduler_params, model_type='cnn')\n",
    "\n",
    "score = model.fit(num_epochs=30)\n",
    "\n",
    "print(score)\n",
    "\n",
    "scores.append(score)\n",
    "legends.append('CNN on oriented images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd66d1-3971-4834-aa5c-24313eab9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Save the results\n",
    "tag = random.randint(0, 2**32)\n",
    "with open(f'results_{tag}', 'wb') as outfi:\n",
    "    pickle.dump((scores, legends), outfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c0292-a109-4dbe-bd4f-963c952a2e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(scores))\n",
    "y = np.array(scores)\n",
    "plt.figure(figsize=(6.4*3, 4.8*3))\n",
    "plt.xticks(x, legends, rotation=90, fontsize=20)\n",
    "plt.plot(x, y, '-')\n",
    "plt.title('Model progression on CV set', fontsize=20)\n",
    "plt.ylabel('Balanced accuracy score', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5855c5ff-39a0-40d2-a249-cc1155008904",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise KeyError('Ended')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca50bac-41ff-4904-ba17-3fa2beabead8",
   "metadata": {},
   "source": [
    "## End of completed analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744aa02f-8b34-4b4a-a18c-cb189a87f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.a Base model on raw data with pca\n",
    "pca_dims = 100\n",
    "model_params = {'penalty': 'l2', 'seed': 14376, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect, not_defect, LogisticRegression, None)\n",
    "score = cla.fit_cv(**model_params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Logitc regression with {pca_dims} dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d670cf85-c9f0-4c7b-addb-31984d3703d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.b Base model on raw data with pca\n",
    "pca_dims = 200\n",
    "model_params = {'penalty': 'l2', 'seed': 14376, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect, not_defect, LogisticRegression, None)\n",
    "score = cla.fit_cv(**model_params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Logitc regression with {pca_dims} dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e557ad-bfef-4627-b92b-a8a0bc0da769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.c Base model on raw data with pca\n",
    "pca_dims = 400\n",
    "model_params = {'penalty': 'l2', 'seed': 14376, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect, not_defect, LogisticRegression, None)\n",
    "score = cla.fit_cv(**model_params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Logitc regression with {pca_dims} dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05cc6a9-6884-426a-be2c-476090c6895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.d Base model on raw data with pca\n",
    "pca_dims = 800\n",
    "model_params = {'penalty': 'l2', 'seed': 14376, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect, not_defect, LogisticRegression, None)\n",
    "score = cla.fit_cv(**model_params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Logitc regression with {pca_dims} dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672c6e4f-95fc-4154-bff3-8e3688627588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.d Base model on raw data with pca\n",
    "pca_dims = 2000\n",
    "model_params = {'penalty': 'l2', 'seed': 14376, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect, not_defect, LogisticRegression, None)\n",
    "score = cla.fit_cv(**model_params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Logitc regression with {pca_dims} dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd5ae9-5dfa-4a0e-bf04-5bb4830dde53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3.a Gradient Boosted Classifier \n",
    "pca_dims = 100\n",
    "params = {'seed': 14376,'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect, not_defect, GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit_cv(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Gradient Boosted Classifier model with {pca_dims} dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c96677-e826-424e-b525-f7e99e4322f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.b Gradient Boosted Classifier \n",
    "pca_dims = 200\n",
    "params = {'seed': 14376,'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect, not_defect, GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit_cv(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Gradient Boosted Classifier model with {pca_dims} dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b82c661-3d5e-4760-9427-20613d4a2737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.c Gradient Boosted Classifier \n",
    "pca_dims = 400\n",
    "params = {'seed': 14376,'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect, not_defect, GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit_cv(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Gradient Boosted Classifier model with {pca_dims} dimensions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756438c5-ae42-4c39-a70f-856e0659c667",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fix orientation of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15faccb1-ffd9-4384-ad28-91b1705237f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from app.custom import Orient\n",
    "# Get the oriented images and HOG\n",
    "start = time.perf_counter()\n",
    "oriented_defect = Orient(num_jobs=20, do_debug=True, do_eliminate=False) << defect\n",
    "oriented_not_defect = Orient(num_jobs=20, do_debug=True, do_eliminate=False) << not_defect\n",
    "print(time.perf_counter() - start)\n",
    "\n",
    "# View both the defect and the clean class\n",
    "# I am using + operator as oriented_defect and oriented_clean are tuples\n",
    "_ = Show(num_images=10, seed=seed) << oriented_defect + oriented_not_defect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16acad03-ce92-4289-8ceb-358deba39c46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Gradient Boosted classifier on oriented defects\n",
    "pca_dims = 200\n",
    "params = {'seed': 14376,'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': pca_dims}\n",
    "cla = Classifier(oriented_defect[-1], oriented_not_defect[-1], GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit_cv(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Gradient Boosted Classifier model with {pca_dims} dimensions and re-oriented images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271c7bc-0bbc-475e-aba2-5fa4a9aa4f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for misclass in out:\n",
    "    _ = Show(num_images=10, seed=seed) << misclass[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f997665-3a5a-4776-bdb6-c66228d2baee",
   "metadata": {},
   "source": [
    "# Sobel Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63844e6-7b3e-461f-9aef-01b973ffe243",
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_kernel = CreateKernel(kernel='sobel', axis=0) << oriented_defect\n",
    "not_defect_kernel = CreateKernel(kernel='sobel', axis=0) << oriented_not_defect\n",
    "\n",
    "sobel_defect = Convolve() << defect_kernel\n",
    "sobel_not_defect = Convolve() << not_defect_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ebdec7-61bc-4ef4-9983-78dee6ae256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dims = 100\n",
    "params = {'seed': 14376,'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': pca_dims}\n",
    "cla = Classifier(oriented_defect[-1] & sobel_defect[-1], oriented_not_defect[-1] & sobel_not_defect[-1], GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit_cv(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Gradient Boosted Classifier model with {pca_dims} dimensions and Sobel images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759cfce-486c-40eb-8967-18add8afeb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dims = 200\n",
    "params = {'seed': 14376,'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': pca_dims}\n",
    "cla = Classifier(oriented_defect[-1] & sobel_defect[-1], oriented_not_defect[-1] & sobel_not_defect[-1], GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit_cv(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Gradient Boosted Classifier model with {pca_dims} dimensions and Sobel images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73eaca2-5678-4d45-82b2-9c7bb13aa991",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dims = 400\n",
    "params = {'seed': 14376,'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': pca_dims}\n",
    "cla = Classifier(oriented_defect[-1] & sobel_defect[-1], oriented_not_defect[-1] & sobel_not_defect[-1], GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit_cv(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Gradient Boosted Classifier model with {pca_dims} dimensions and Sobel images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f2d37-b330-4093-8a23-c6509247d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for misclass in out:\n",
    "    _ = Show(num_images=40, seed=seed) << misclass[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08095d06-ecf8-407a-8c41-249522fb8865",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Highlight the front grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace01ee-4cd9-4f67-a5b0-b76641117349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the BusBars\n",
    "front_grid_params = {'finger_width': 5, 'finger_height': 5, 'side_padding': 2, \n",
    "                     'top_padding': 0, 'bottom_padding': 0, 'finger_mult': 1, \n",
    "                     'flipped': False, 'num_jobs': 40}\n",
    "grid_oriented_defect = HighlightFrontGrid(**front_grid_params) << oriented_defect\n",
    "grid_oriented_not_defect = HighlightFrontGrid(**front_grid_params) << oriented_not_defect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d323df4d-9a53-4ef6-9772-3c1d4d1758bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_ = oriented_defect[-1]  & grid_oriented_defect[-1] & sobel_defect[-1]\n",
    "not_defect_ = oriented_not_defect[-1] & grid_oriented_not_defect[-1] & sobel_not_defect[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d5d943-6142-46f1-abc5-2450834582ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dims = 70\n",
    "params = {'seed': 14376,'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect_, not_defect_, GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit_cv(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Gradient Boosted Classifier model with {pca_dims} dimensions and sobel + custom kernel_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504c995-94f7-42c9-9e8c-22657c1143c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(legends)\n",
    "scores[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32e08c-f519-47f5-9155-3a588b0b720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dims = 100\n",
    "params = {'seed': 14376,'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect_, not_defect_, GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit_cv(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Gradient Boosted Classifier model with {pca_dims} dimensions and sobel + custom kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aafa95-5e73-4112-9c5c-eb17bd4a6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dims = 200\n",
    "params = {'seed': 14376,'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect_, not_defect_, GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit_cv(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Gradient Boosted Classifier model with {pca_dims} dimensions and sobel + custom kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ba35fc-6c71-4dd6-a48e-7977361abecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dims = 400\n",
    "params = {'seed': 14376,'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': pca_dims}\n",
    "cla = Classifier(defect_, not_defect_, GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit_cv(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "scores.append(score)\n",
    "legends.append(f'Gradient Boosted Classifier model with {pca_dims} dimensions and sobel + custom kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20952789-c7d9-4da5-9ec6-b01f505764d1",
   "metadata": {},
   "source": [
    "## Deep Neural net models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0cd7b7-1c39-44c5-9c9e-95aad3967320",
   "metadata": {},
   "outputs": [],
   "source": [
    "defect_dnn = oriented_defect[-1] & sobel_defect[-1]\n",
    "not_defect_dnn = oriented_not_defect[-1] & sobel_not_defect[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037b12b-cf45-4e70-968f-d980e9324eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.models import ModelNN\n",
    "\n",
    "lr = 0.00005\n",
    "pca_dims = 1000\n",
    "if pca_dims is None:\n",
    "    dense_layers = (2000, 1000, 300, 300, 300)\n",
    "else:\n",
    "    dense_layers = (pca_dims, int(pca_dims/2), int(pca_dims/2), int(pca_dims/2), int(pca_dims/2))\n",
    "\n",
    "optimizer_params = {'name': 'sgd', 'lr': lr, 'nesterov': False, 'momentum': 0.9}\n",
    "scheduler_params = {'lr_min': lr/100, 't_mul': 2}\n",
    "model_params = {'num_output_classes': 2, 'dense_layers': (2000, 1000, 300, 300, 300), 'dense_activation': 'relu', \n",
    "                'pca_dims': pca_dims, 'dropout': 0.2}\n",
    "\n",
    "# model = ModelNN(defect, not_defect, model_params, optimizer_params, scheduler_params, model_type='dnn')\n",
    "model = ModelNN(defect_dnn, not_defect_dnn, model_params, optimizer_params, scheduler_params, model_type='dnn')\n",
    "score = model.fit(num_epochs=30)\n",
    "\n",
    "print(score)\n",
    "scores.append(score)\n",
    "legends.append(f'DNN with {pca_dims} dims on enhanced images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728110ba-8694-4291-b201-c97906c83a55",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## CNN on the original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc3564d-4d82-4f3c-aa80-2f5ef06f92f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from app.models import ModelNN\n",
    "\n",
    "lr = 0.0002\n",
    "optimizer_params = {'name': 'sgd', 'lr': lr, 'nesterov': True, 'momentum': 0.9}\n",
    "scheduler_params = {'lr_min': lr/100, 't_mul': 3}\n",
    "model_params = {'num_output_classes': 2, 'channels': ((1, 5), (10, 3), (10, 3), (10, 3), (10, 3)), 'dense_layers': (1000, 500, 500)}\n",
    "\n",
    "model = ModelNN(oriented_defect[-1], oriented_not_defect[-1], model_params, optimizer_params, scheduler_params, model_type='cnn')\n",
    "\n",
    "score = model.fit(num_epochs=30)\n",
    "\n",
    "print(score)\n",
    "\n",
    "scores.append(score)\n",
    "legends.append('CNN on oriented images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e66559-422d-4d39-8595-a85652812da5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Save the results\n",
    "tag = random.randint(0, 2**32)\n",
    "with open(f'results_{tag}', 'wb') as outfi:\n",
    "    pickle.dump((scores, legends), outfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af42052-af84-40f3-91af-0a4420d9b953",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x = np.arange(len(scores))\n",
    "y = np.array(scores)\n",
    "plt.figure(figsize=(6.4*3, 4.8*3))\n",
    "plt.xticks(x, legends, rotation=90, fontsize=20)\n",
    "plt.plot(x, y, '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0752467-3dc8-4217-9748-d9a023ad9ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "scores, legends = pickle.load(open(f'results_{tag}', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ba8d38-85d5-4b22-99f9-4fb2c5593743",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0, 5, 6, -1, -6, -5]\n",
    "new_legends = []\n",
    "new_scores = []\n",
    "for index in indices:\n",
    "    new_legends.append(legends[index])\n",
    "    new_scores.append(scores[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca6303f-c8f1-4a2e-b046-313aad66a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2d860-f31e-4cf3-8922-919c13644cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(len(new_scores))\n",
    "y = np.array(new_scores)\n",
    "plt.figure(figsize=(6.4*3, 4.8*3))\n",
    "plt.xticks(x, new_legends, rotation=90, fontsize=20)\n",
    "plt.plot(x, y, '-')\n",
    "plt.title('Model progression on CV set', fontsize=20)\n",
    "plt.ylabel('Balanced accuracy score', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca09ebb-9aca-4e35-a6be-7a37b4e6fe2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raise KeyError(\"Ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10beed19-906f-4fb5-96e9-a00553536f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ~oriented_defect[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb7ed94-49c3-4e39-928f-5b2513578169",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1c83a-d4e5-41e9-9c61-02ea6263dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = 1 - CreateOnesMask(images).horizontal_from_center(left_width=96, right_width=96, height=10, val=0)\n",
    "mask = 1 - CreateOnesMask(images).vertical_from_center(top_height=96, bottom_height=96, width=10, val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e427f84-2072-4097-98e8-2f7d5afd1c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_images = (IFFT(mask=mask) << (FFT(window=None) << oriented_defect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63501cda-57d3-497d-8f85-91c8cb4940e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = Show(num_images=10, seed=seed) << (oriented_defect[-1], masked_images[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0747fe1a-dba8-4b27-bc55-ac9ed6b79993",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3abf8-a463-4b03-9a2f-e12bf8ac42f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'seed': 14376,'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'pca_dims': 250}\n",
    "# cla = Classifier(grid_defect[-1] & defect, grid_not_defect[-1] & not_defect, GradientBoostingClassifier, None)\n",
    "cla = Classifier(oriented_defect[-1] & grid_oriented_defect[-1], oriented_not_defect[-1] & grid_oriented_not_defect[-1], GradientBoostingClassifier, None)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit(**params)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330fea0-f4f1-41a5-a87d-5577c7ac0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "front_grid_params = {'finger_width': 4, 'finger_height': 5, 'side_padding': 2, 'top_padding': 0, 'bottom_padding': 0, 'finger_mult': 1, 'flipped': False, 'num_jobs': 20}\n",
    "clean = (DefectViewer(row_chop=15, col_chop=15) << (ImageLoader(defect_class='None', is_not=False) << 10000))\n",
    "oriented_clean= Orient(num_jobs=20) << clean\n",
    "oriented_grid_clean = HighlightFrontGrid(**front_grid_params) << oriented_clean\n",
    "print(time.perf_counter()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4e6700-7356-44e6-9301-51588ff5f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_clean = oriented_clean[-1] & oriented_grid_clean[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18c6b66-0f12-47a9-9ead-1a3947a91b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals = cla.predict(oriented_clean[-1] & oriented_grid_clean[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7b1297-ad31-415a-9ac4-7554f0bb4c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02305eb-682e-4f70-b312-09e7bbd314a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented = pd.read_csv('../data/andi_segmented.csv').set_index('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db881e83-2c8d-4651-8d83-1227a3f4bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_get_input(img):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6.4*1.5, 4.8*1.5))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    a = input()\n",
    "    plt.close()\n",
    "    clear_output()\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044210d-ebbd-4de7-b25b-c1ed29947f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "y_count = 0\n",
    "for y, filename, image  in zip(y_vals, concat_clean.image_labels, concat_clean.images):\n",
    "    if y and np.any(segmented.at[filename, 'clean']):\n",
    "        \n",
    "        a = display_get_input(image)\n",
    "        if a == 'y':\n",
    "            segmented.at[filename, 'clean'] = False\n",
    "            count += 1\n",
    "            print(f'Count is {count} y-count is {y_count}')\n",
    "    elif y:\n",
    "        y_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56060dba-e120-4574-9813-9ae59d78070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented.to_csv('../data/andi_segmented.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a529ed-2d26-4fe6-8c50-a4e30696a24d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Clean up None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46774b76-e09b-43a1-9310-2be78d4aa348",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(out[0][0].images.shape[0]):\n",
    "    image = out[0][0].images[i, :, :]\n",
    "    filename = out[0][0].image_labels[i]\n",
    "    a = display_get_input(image)\n",
    "    if a == 't':\n",
    "        segmented.at[filename, 'clean'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb2941-620e-4529-aada-0bfe8004dd20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "segmented.to_csv('../data/andi_segmented.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0960d7b-9d89-4609-bd5c-e45043a296c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cleanup front grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93639c7-4a9f-4040-bf34-5927521e26f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keep_front_grid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6509fd-7fec-4a07-ac4d-a38085f7b9b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def display_get_input(filename):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if os.path.exists(f'../data/images/train/{filename}'):\n",
    "        filepath = f'../data/images/train/{filename}'\n",
    "    else:\n",
    "        filepath = f'../data/images/test/{filename}'\n",
    "\n",
    "    image = cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    plt.figure(figsize=(6.4*1.5, 4.8*1.5))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()\n",
    "    a = input()\n",
    "    plt.close()\n",
    "    clear_output()\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e5970-b787-473c-aef4-fdafef899170",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "annotations_df = pd.read_csv(\"../data/processed_annotations.csv\")\n",
    "annotations_df = annotations_df[annotations_df['defect_class'] == 'FrontGridInterruption']\n",
    "annotations_df = annotations_df.groupby('filename').head(1)\n",
    "annotations_df = annotations_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9339f3-d89b-4892-82ac-be26f9147cc2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "frontgrid_df = annotations_df[annotations_df['filename'].isin(keep_front_grid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3054e61-e778-4dc6-8f9e-97e5657c3dee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# frontgrid_df.to_csv('../data/front_grid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be722b3b-4816-4461-8890-e633101d451e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Previous work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4bd184-ee08-438d-a5fb-9d7c81cff8d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the BusBars\n",
    "nobus_defect = RemoveBusBars() << oriented_defect\n",
    "nobus_clean = RemoveBusBars() << oriented_clean\n",
    "\n",
    "_ = Show(num_images=5, seed=seed) << nobus_defect + nobus_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7f68c-cc63-4200-81f8-4c232b93c574",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "front_grid_defect = HighlightFrontGrid() << nobus_defect\n",
    "front_grid_clean = HighlightFrontGrid() << nobus_clean\n",
    "\n",
    "_ = Show(num_images=15, seed=seed) << front_grid_defect + front_grid_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de413c-56b8-499f-9601-75496de574ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sigmoid_defect = Exposure('dynamic_sigmoid', cutoff=0.6, gain=50) << front_grid_defect\n",
    "sigmoid_clean = Exposure('dynamic_sigmoid', cutoff=0.6, gain=50) << front_grid_clean\n",
    "\n",
    "_ = Show(num_images=10, seed=seed) << (defect, ) + sigmoid_defect + (clean,) + sigmoid_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd947e-9f12-4b9e-97be-2c4d44f42ef6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hog_front_defect = HOG(pixels_per_cell=(5, 5), num_jobs=20) << sigmoid_defect\n",
    "hog_front_clean = HOG(pixels_per_cell=(5, 5), num_jobs=20) << sigmoid_clean\n",
    "\n",
    "_ = Show(num_images=10, seed=seed) << (defect, ) + hog_front_defect + (clean,) + hog_front_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b1e37c-4c41-4dc3-8df8-b9b3ff1a60f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374dbf83-e5e2-4a32-a301-e5d118f08ec5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ec377-5e8f-4e94-968a-5ae92d1182b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Base model on raw data\n",
    "model_params = {'penalty': 'l2', 'seed': 14376, 'pca_dims': 100}\n",
    "cla = Classifier(defect, clean, LogisticRegression, None)\n",
    "score = cla.fit(**model_params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5caf21-1d42-479c-90e4-62d806700977",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2. HOG on RAW data\n",
    "model_params = {'penalty': 'l2', 'seed': 14376, 'pca_dims': 100, 'num_jobs': 20}\n",
    "cla = Classifier(defect, clean, LogisticRegression, HOG)\n",
    "score = cla.fit(**model_params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f05aa8c-d2af-4ead-ae32-bf05946ea610",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for imw in out:\n",
    "    print(imw[-1].images.shape[0])\n",
    "    Show(num_images=20) << imw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e750c-78c1-4705-b5d7-ceb0a76fa01f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3. HOG on rotated data\n",
    "model_params = {'penalty': 'l2', 'seed': 14376, 'pca_dims': 100, 'num_jobs': 20}\n",
    "cla = Classifier(oriented_defect[-1], oriented_clean[-1], LogisticRegression, HOG)\n",
    "score = cla.fit(**model_params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c17ed0-c19f-406c-bcf6-c2a9ac0a35fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 4. HighlightFrontGrid on rotated data\n",
    "model_params = {'penalty': 'l2', 'seed': 14376, 'pca_dims': 100, 'num_jobs': 20, 'reduce_max': 1, 'finger_mult': 1}\n",
    "cla = Classifier(oriented_defect[-1], oriented_clean[-1], LogisticRegression, HighlightFrontGrid)\n",
    "score = cla.fit(**model_params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e8477-b7bc-46f7-b20a-19808ab033a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for imw in out:\n",
    "    print(imw[-1].images.shape[0])\n",
    "    Show(num_images=20) << imw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a486775f-022e-4b81-9126-9a5ae86c5954",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## End of completed work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99b9cd-7e88-48e5-b0e3-786e78f6fa61",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# params = {'seed': 14376,'penalty': 'l2', 'pca_dims': 238, 'num_jobs': 20, 'reduce_max': 1, \n",
    "#           'finger_mult': 52.28, 'padding_mult': 17, 'max_finger_width': 3, 'finger_height': 43}\n",
    "params = {'seed': 14376,'penalty': 'l2', 'pca_dims': 200, 'num_jobs': 20, 'reduce_max': 1, \n",
    "          'finger_mult': 50, 'padding_mult': 4, 'max_finger_width': 4, 'finger_height': 20}\n",
    "cla = Classifier(defect, oriented_clean[-1], LogisticRegression, HighlightFrontGrid)\n",
    "     \n",
    "# When done, return the score \n",
    "score = cla.fit(**params)\n",
    "print(score)\n",
    "\n",
    "# Misclassified\n",
    "conf, out = cla.misclassified()\n",
    "print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "\n",
    "for imw in out:\n",
    "    print(imw[-1].images.shape[0])\n",
    "    Show(num_images=20) << imw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
