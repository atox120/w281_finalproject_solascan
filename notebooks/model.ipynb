{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe32f17",
   "metadata": {},
   "source": [
    "# COMBINED CLASSIFIER\n",
    "\n",
    "This notebook contains the code for the final classifier which returns whether each defect is present in each image or not. The classes included in this classifier include:\n",
    "\n",
    "- FrontGridInterruption, NearSolderPad (Combined) \n",
    "- Closed\n",
    "- Isolated \n",
    "- BrightSpot\n",
    "- Corrosion\n",
    "- Resistive\n",
    "\n",
    "The rough operation of the classifier is as follows. \n",
    "\n",
    "1. Datasets are created calling the ImageLoader and DefectViewer Classes. \n",
    "2. The best pipeline of transformations for each class in stored in the [model_features.py](https://github.com/atox120/w281_finalproject_solascan/blob/main/app/model_features.py) file.\n",
    "3. The parameters for each individual classifier pipeline is then input into the model.\n",
    "4. A loop is then initiated whereby each dataset is loaded, filtered for the correct classes and the transformations applied. The scores for each individual classifier are recorded.\n",
    "5. The scores are then concatenated together and scored using the [VectorClassifier](https://github.com/atox120/w281_finalproject_solascan/blob/f54d9cb7b62f3449f2d393d351ab9cbaf2e0e5fb/app/models.py#L723) class. The balanced accuracy score is used.\n",
    "\n",
    "We present herein comparisons for each pipeline comparing the performance vs. Clean images and vs. all other classes combined separately. \n",
    "\n",
    "In contrast to the EDA notebooks, he scores presented herein are calculated on the TEST set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a901293f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8abce5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import tabulate\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier\n",
    "sys.path.append(os.path.join(os.path.abspath(\"\"), \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b42c493",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from app import model_features\n",
    "from app.models import Classifier\n",
    "from app.model_features import get_samples, get_data_handler\n",
    "from app.imager import ImageLoader, DefectViewer, Show, Exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a52d66f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb05c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complimentary:\n",
    "# If True: Split the data as Category and all other\n",
    "# If False: Split the data as Category and None\n",
    "complimentary = True\n",
    "\n",
    "# Maximum number of samples to choose for defects\n",
    "# The other class is 2X this number\n",
    "num_samples = 2000\n",
    "\n",
    "# Seed for plotting\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3cbc100",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Analyzing which defect types:\n",
    "model_defect_classes = ['Closed', 'Isolated','BrightSpot', 'Corrosion', 'Resistive',\n",
    "                       ('FrontGridInterruption', 'NearSolderPad')]\n",
    "\n",
    "# Analyzing which defect\n",
    "model_params = {'Closed': {'class': GradientBoostingClassifier, 'n_estimators': 300, 'max_depth': 4,\n",
    "                         'learning_rate': 0.1, 'pca_dims': min(160, num_samples)},\n",
    "            'Isolated': {'class': GradientBoostingClassifier, 'n_estimators': 300, 'max_depth': 4,\n",
    "                         'learning_rate': 0.1, 'pca_dims': min(160, num_samples)},\n",
    "            'BrightSpot': {'class': LogisticRegression, 'penalty': 'l2', 'pca_dims': None},\n",
    "            'Corrosion': {'class': LogisticRegression, 'penalty': 'l2', 'pca_dims': None},\n",
    "            'Resistive':  {'class': ExtraTreesClassifier, 'max_features': 0.1, 'min_samples_split': 8,\n",
    "                           'random_state': 32},\n",
    "            ('FrontGridInterruption', 'NearSolderPad'):\n",
    "                        {'class': GradientBoostingClassifier, 'n_estimators': 600, 'max_depth': 4,\n",
    "                         'learning_rate': 0.05, 'pca_dims': min(250, num_samples)},}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e2290",
   "metadata": {},
   "source": [
    "## Main loop for creating models and running evaluations\n",
    "\n",
    "First we set compliment = False, which sets up the dataset for each pipeline to run a binary classification task distinguishing the defect class against a non-defective 'clean' class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06fa872b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Closed\n",
      "model_features.closed\n",
      "0 images were rejected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/notebooks/../app/imager.py:786: RuntimeWarning: invalid value encountered in true_divide\n",
      "  out_img = (in_imgs - all_min) / (all_max - all_min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed on count 367\n",
      "Failed on count 1614\n",
      "2 images were rejected\n",
      "Others\n",
      " Closed - Preprocessed\n",
      "Completed Closed in 114.68839525801013s\n",
      "Working on Isolated\n",
      "model_features.isolated\n",
      "Others\n",
      " Isolated - Preprocessed\n",
      "Completed Isolated in 30.336396701983176s\n",
      "Working on BrightSpot\n",
      "model_features.brightspots\n",
      "0 were rejected\n",
      "0 were rejected\n",
      "Others\n",
      " Brightspots - Gaussian Blur - Fourier Transform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed BrightSpot in 15.498162627976853s\n",
      "Working on Corrosion\n",
      "model_features.generic_return\n",
      "Others\n",
      " processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Corrosion in 5.011916688992642s\n",
      "Working on Resistive\n",
      "model_features.resistive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/notebooks/../app/transforms.py:203: RuntimeWarning: divide by zero encountered in log10\n",
      "  magnitude = np.log10(np.abs(transformed))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others\n",
      " ResistiveCrack - Preprocessed\n",
      "Completed Resistive in 450.1302660870133s\n",
      "Working on ('FrontGridInterruption', 'NearSolderPad')\n",
      "model_features.grid_interruption\n",
      "Others\n",
      " GridInterruption - Preprocessed\n",
      "Completed ('FrontGridInterruption', 'NearSolderPad') in 245.0291437790147s\n"
     ]
    }
   ],
   "source": [
    "# Empty objects for storing scores\n",
    "model_objects = []\n",
    "model_classes = []\n",
    "model_data_handlers = []\n",
    "\n",
    "# For each defect class, create the DataSet\n",
    "for cnt, defect_classes in enumerate(model_defect_classes):\n",
    "    if len(model_objects) >= cnt + 1:\n",
    "        continue\n",
    "        \n",
    "    print(f'Working on {defect_classes}')\n",
    "    start = time.perf_counter()\n",
    "    model_param = model_params[defect_classes]\n",
    "    \n",
    "    # Get the samples for the model\n",
    "    if isinstance(defect_classes, tuple):\n",
    "        classes = list(defect_classes)\n",
    "    else:\n",
    "        classes = defect_classes\n",
    "    \n",
    "    # Get the data for modeling\n",
    "    defect, not_defect = get_samples(classes, num_samples, complimentary=complimentary)\n",
    "    \n",
    "    # Get the data handler \n",
    "    data_handler = get_data_handler(defect_classes)\n",
    "    \n",
    "    # Get the pre processed data for this \n",
    "    defect_ = data_handler(defect, num_jobs=20)\n",
    "    not_defect_ = data_handler(not_defect, num_jobs=20)\n",
    "    print(not_defect_.category)\n",
    "    \n",
    "    # Show the pre and post processed images\n",
    "    # _ = Show(num_images=2, seed=seed) << (defect, defect_) + (not_defect, not_defect_)\n",
    "    \n",
    "    # Get the parameter for this classifier\n",
    "    this_param = copy.deepcopy(model_param)\n",
    "    model_class = this_param['class']\n",
    "    del this_param['class']\n",
    "    \n",
    "#     # Train the classifier \n",
    "#     print(defect_classes)\n",
    "#     cla = Classifier(defect_, not_defect_, model_class, None)\n",
    "#     score = cla.fit_cv(**this_param)\n",
    "    \n",
    "#     # Misclassified\n",
    "#     print(score)\n",
    "#     conf, out = cla.misclassified()\n",
    "#     print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "    \n",
    "    # Train the classifier \n",
    "    cla = Classifier(defect_, not_defect_, model_class, None)\n",
    "    model = cla.fit(**this_param)\n",
    "    \n",
    "    model_objects.append(model)\n",
    "    model_classes.append(defect_classes)\n",
    "    model_data_handlers.append(data_handler)\n",
    "    \n",
    "    print(f'Completed {defect_classes} in {time.perf_counter()-start}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12385bb9",
   "metadata": {},
   "source": [
    "### Combine the models together and calculate score\n",
    "\n",
    "In this step, the individual classifier scores are combined to obtain the overall multiclass classification score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a0b1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ImageLoader(defect_class=None, do_train=False)\n",
    "filename_df = img.get(n=1000)\n",
    "filename_df = DefectViewer(row_chop=15, col_chop=15).get(filename_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e378a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Closed',), ('Isolated',), ('BrightSpot',), ('Corrosion',), ('Resistive',), ('FrontGridInterruption', 'NearSolderPad')]\n"
     ]
    }
   ],
   "source": [
    "from app.models import VectorClassifier\n",
    "\n",
    "# Instantiate vector classifier object. \n",
    "vc = VectorClassifier(model_objects=model_objects, model_classes=model_classes, \n",
    "                      model_data_handlers=model_data_handlers, defect_classes=img.defect_classes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03da8928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images were rejected\n",
      "0 were rejected\n",
      "('Closed',) 0.7786319232590668 0.8281329561527582\n",
      "('Isolated',) 0.8280570289916085 0.8874903474903475\n",
      "('BrightSpot',) 0.966900702106319 0.9942857142857142\n",
      "('Corrosion',) 0.9954864593781344 1.0\n",
      "('Resistive',) 0.726774322169059 0.8064610389610389\n",
      "('FrontGridInterruption', 'NearSolderPad') 0.6425420046109701 0.7015270935960591\n",
      "{'Overall': (0.7691355866605709, 0.8072675026123302), ('Closed',): (0.7786319232590668, 0.8281329561527582), ('Isolated',): (0.8280570289916085, 0.8874903474903475), ('BrightSpot',): (0.966900702106319, 0.9942857142857142), ('Corrosion',): (0.9954864593781344, 1.0), ('Resistive',): (0.726774322169059, 0.8064610389610389), ('FrontGridInterruption', 'NearSolderPad'): (0.6425420046109701, 0.7015270935960591)}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set. \n",
    "results = vc.test(filename_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "415d2f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, 0.7691355866605709, 0.8072675026123302\n",
      "('Closed',), 0.7786319232590668, 0.8281329561527582\n",
      "('Isolated',), 0.8280570289916085, 0.8874903474903475\n",
      "('BrightSpot',), 0.966900702106319, 0.9942857142857142\n",
      "('Corrosion',), 0.9954864593781344, 1.0\n",
      "('Resistive',), 0.726774322169059, 0.8064610389610389\n",
      "('FrontGridInterruption', 'NearSolderPad'), 0.6425420046109701, 0.7015270935960591\n"
     ]
    }
   ],
   "source": [
    "for key, value in results.items():\n",
    "    print(f'{key}, {value[0]}, {value[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8edeb6a",
   "metadata": {},
   "source": [
    "##  Vs All Other Defects\n",
    "\n",
    "Now we run the classifier whereby the classification is set up to distinguish a single defect class vs all other possible defect classes, includeing the no defect present class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfbc3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complimentary = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55f32ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Closed\n",
      "model_features.closed\n",
      "0 images were rejected\n",
      "0 images were rejected\n",
      "None\n",
      " Closed - Preprocessed\n",
      "Completed Closed in 114.54465924098622s\n",
      "Working on Isolated\n",
      "model_features.isolated\n",
      "None\n",
      " Isolated - Preprocessed\n",
      "Completed Isolated in 29.737355699006002s\n",
      "Working on BrightSpot\n",
      "model_features.brightspots\n",
      "0 were rejected\n",
      "0 were rejected\n",
      "None\n",
      " Brightspots - Gaussian Blur - Fourier Transform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed BrightSpot in 15.741276284999913s\n",
      "Working on Corrosion\n",
      "model_features.generic_return\n",
      "None\n",
      " processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Corrosion in 5.0324290769931395s\n",
      "Working on Resistive\n",
      "model_features.resistive\n",
      "None\n",
      " ResistiveCrack - Preprocessed\n",
      "Completed Resistive in 508.93710093200207s\n",
      "Working on ('FrontGridInterruption', 'NearSolderPad')\n",
      "model_features.grid_interruption\n",
      "None\n",
      " GridInterruption - Preprocessed\n",
      "Completed ('FrontGridInterruption', 'NearSolderPad') in 247.02336497200304s\n"
     ]
    }
   ],
   "source": [
    "# Empty objects for storing scores\n",
    "model_objects = []\n",
    "model_classes = []\n",
    "model_data_handlers = []\n",
    "\n",
    "# For each defect class, create the DataSet\n",
    "for cnt, defect_classes in enumerate(model_defect_classes):\n",
    "    if len(model_objects) >= cnt + 1:\n",
    "        continue\n",
    "        \n",
    "    print(f'Working on {defect_classes}')\n",
    "    start = time.perf_counter()\n",
    "    model_param = model_params[defect_classes]\n",
    "    \n",
    "    # Get the samples for the model\n",
    "    if isinstance(defect_classes, tuple):\n",
    "        classes = list(defect_classes)\n",
    "    else:\n",
    "        classes = defect_classes\n",
    "    \n",
    "    # Get the data for modeling\n",
    "    defect, not_defect = get_samples(classes, num_samples, complimentary=complimentary)\n",
    "    \n",
    "    # Get the data handler \n",
    "    data_handler = get_data_handler(defect_classes)\n",
    "    \n",
    "    # Get the pre processed data for this \n",
    "    defect_ = data_handler(defect, num_jobs=20)\n",
    "    not_defect_ = data_handler(not_defect, num_jobs=20)\n",
    "    print(not_defect_.category)\n",
    "    \n",
    "    # Show the pre and post processed images\n",
    "    # _ = Show(num_images=2, seed=seed) << (defect, defect_) + (not_defect, not_defect_)\n",
    "    \n",
    "    # Get the parameter for this classifier\n",
    "    this_param = copy.deepcopy(model_param)\n",
    "    model_class = this_param['class']\n",
    "    del this_param['class']\n",
    "    \n",
    "#     # Train the classifier \n",
    "#     print(defect_classes)\n",
    "#     cla = Classifier(defect_, not_defect_, model_class, None)\n",
    "#     score = cla.fit_cv(**this_param)\n",
    "    \n",
    "#     # Misclassified\n",
    "#     print(score)\n",
    "#     conf, out = cla.misclassified()\n",
    "#     print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "    \n",
    "    # Train the classifier \n",
    "    cla = Classifier(defect_, not_defect_, model_class, None)\n",
    "    model = cla.fit(**this_param)\n",
    "    \n",
    "    model_objects.append(model)\n",
    "    model_classes.append(defect_classes)\n",
    "    model_data_handlers.append(data_handler)\n",
    "    \n",
    "    print(f'Completed {defect_classes} in {time.perf_counter()-start}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20bcae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Closed',), ('Isolated',), ('BrightSpot',), ('Corrosion',), ('Resistive',), ('FrontGridInterruption', 'NearSolderPad')]\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset to obtain the scoring information. \n",
    "img = ImageLoader(defect_class=None, do_train=False)\n",
    "filename_df = img.get(n=1000)\n",
    "filename_df = DefectViewer(row_chop=15, col_chop=15).get(filename_df)\n",
    "\n",
    "# Instantiate a new vector classifier class \n",
    "vc = VectorClassifier(model_objects=model_objects, model_classes=model_classes, \n",
    "                      model_data_handlers=model_data_handlers, defect_classes=img.defect_classes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fec1007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, 0.7691355866605709, 0.8072675026123302\n",
      "('Closed',), 0.7786319232590668, 0.8281329561527582\n",
      "('Isolated',), 0.8280570289916085, 0.8874903474903475\n",
      "('BrightSpot',), 0.966900702106319, 0.9942857142857142\n",
      "('Corrosion',), 0.9954864593781344, 1.0\n",
      "('Resistive',), 0.726774322169059, 0.8064610389610389\n",
      "('FrontGridInterruption', 'NearSolderPad'), 0.6425420046109701, 0.7015270935960591\n"
     ]
    }
   ],
   "source": [
    "for key, value in results.items():\n",
    "    print(f'{key}, {value[0]}, {value[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f36feab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
