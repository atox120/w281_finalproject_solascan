{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9062028",
   "metadata": {},
   "source": [
    "# COMBINED CLASSIFIER\n",
    "\n",
    "This notebook contains the code for the final classifier which returns whether each defect is present in each image or not. The classes included in this classifier include:\n",
    "\n",
    "- FrontGridInterruption, NearSolderPad (Combined) \n",
    "- Closed\n",
    "- Isolated \n",
    "- BrightSpot\n",
    "- Corrosion\n",
    "- Resistive\n",
    "\n",
    "The rough operation of the classifier is as follows. \n",
    "\n",
    "1. Datasets are created calling the ImageLoader and DefectViewer Classes. \n",
    "2. The best pipeline of transformations for each class in stored in the [model_features.py](https://github.com/atox120/w281_finalproject_solascan/blob/main/app/model_features.py) file.\n",
    "3. The parameters for each individual classifier pipeline is then input into the model.\n",
    "4. A loop is then initiated whereby each dataset is loaded, filtered for the correct classes and the transformations applied. The scores for each individual classifier are recorded.\n",
    "5. The scores are then concatenated together and scored using the [VectorClassifier](https://github.com/atox120/w281_finalproject_solascan/blob/f54d9cb7b62f3449f2d393d351ab9cbaf2e0e5fb/app/models.py#L723) class. The balanced accuracy score is used.\n",
    "\n",
    "We present herein comparisons for each pipeline comparing the performance vs. Clean images and vs. all other classes combined separately. \n",
    "\n",
    "In contrast to the EDA notebooks, he scores presented herein are calculated on the TEST set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4c4592",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1252b839",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import tabulate\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier\n",
    "sys.path.append(os.path.join(os.path.abspath(\"\"), \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c28b4b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from app import model_features\n",
    "from app.models import Classifier\n",
    "from app.model_features import get_samples, get_data_handler\n",
    "from app.imager import ImageLoader, DefectViewer, Show, Exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf6109",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "463c662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complimentary:\n",
    "# If True: Split the data as Category and all other\n",
    "# If False: Split the data as Category and None\n",
    "complimentary = False\n",
    "\n",
    "# Maximum number of samples to choose for defects\n",
    "# The other class is 2X this number\n",
    "num_samples = 2000\n",
    "\n",
    "# Seed for plotting\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e9ecb3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Analyzing which defect types:\n",
    "model_defect_classes = [('FrontGridInterruption', 'NearSolderPad'), 'Closed', 'Isolated', \n",
    "                        'BrightSpot', 'Corrosion', 'Resistive']\n",
    "\n",
    "# Analyzing which defect\n",
    "model_params = {('FrontGridInterruption', 'NearSolderPad'):\n",
    "            {'class': GradientBoostingClassifier, 'n_estimators': 600, 'max_depth': 4,\n",
    "             'learning_rate': 0.05, 'pca_dims': min(250, num_samples)},\n",
    "            'Closed': {'class': GradientBoostingClassifier, 'n_estimators': 300, 'max_depth': 4,\n",
    "                         'learning_rate': 0.1, 'pca_dims': min(160, num_samples)},\n",
    "            'Isolated': {'class': GradientBoostingClassifier, 'n_estimators': 300, 'max_depth': 4,\n",
    "                         'learning_rate': 0.1, 'pca_dims': min(160, num_samples)},\n",
    "            'BrightSpot': {'class': LogisticRegression, 'penalty': 'l2', 'pca_dims': None},\n",
    "            'Corrosion': {'class': LogisticRegression, 'penalty': 'l2', 'pca_dims': None},\n",
    "            'Resistive':  {'class': ExtraTreesClassifier, 'max_features': 0.1, 'min_samples_split': 8,\n",
    "                           'random_state': 32}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304bc055",
   "metadata": {},
   "source": [
    "## Main loop for creating models and running evaluations\n",
    "\n",
    "First we set compliment = False, which sets up the dataset for each pipeline to run a binary classification task distinguishing the defect class against a non-defective 'clean' class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d3f89",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ('FrontGridInterruption', 'NearSolderPad')\n",
      "model_features.grid_interruption\n"
     ]
    }
   ],
   "source": [
    "# Empty objects for storing scores\n",
    "model_objects = []\n",
    "model_classes = []\n",
    "model_data_handlers = []\n",
    "\n",
    "# For each defect class, create the DataSet\n",
    "for cnt, defect_classes in enumerate(model_defect_classes):\n",
    "    if len(model_objects) >= cnt + 1:\n",
    "        continue\n",
    "        \n",
    "    print(f'Working on {defect_classes}')\n",
    "    start = time.perf_counter()\n",
    "    model_param = model_params[defect_classes]\n",
    "    \n",
    "    # Get the samples for the model\n",
    "    if isinstance(defect_classes, tuple):\n",
    "        classes = list(defect_classes)\n",
    "    else:\n",
    "        classes = defect_classes\n",
    "    \n",
    "    # Get the data for modeling\n",
    "    defect, not_defect = get_samples(classes, num_samples, complimentary=complimentary)\n",
    "    \n",
    "    # Get the data handler \n",
    "    data_handler = get_data_handler(defect_classes)\n",
    "    \n",
    "    # Get the pre processed data for this \n",
    "    defect_ = data_handler(defect, num_jobs=20)\n",
    "    not_defect_ = data_handler(not_defect, num_jobs=20)\n",
    "    print(not_defect_.category)\n",
    "    \n",
    "    # Show the pre and post processed images\n",
    "    # _ = Show(num_images=2, seed=seed) << (defect, defect_) + (not_defect, not_defect_)\n",
    "    \n",
    "    # Get the parameter for this classifier\n",
    "    this_param = copy.deepcopy(model_param)\n",
    "    model_class = this_param['class']\n",
    "    del this_param['class']\n",
    "    \n",
    "#     # Train the classifier \n",
    "#     print(defect_classes)\n",
    "#     cla = Classifier(defect_, not_defect_, model_class, None)\n",
    "#     score = cla.fit_cv(**this_param)\n",
    "    \n",
    "#     # Misclassified\n",
    "#     print(score)\n",
    "#     conf, out = cla.misclassified()\n",
    "#     print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "    \n",
    "    # Train the classifier \n",
    "    cla = Classifier(defect_, not_defect_, model_class, None)\n",
    "    model = cla.fit(**this_param)\n",
    "    \n",
    "    model_objects.append(model)\n",
    "    model_classes.append(defect_classes)\n",
    "    model_data_handlers.append(data_handler)\n",
    "    \n",
    "    print(f'Completed {defect_classes} in {time.perf_counter()-start}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7a0384",
   "metadata": {},
   "source": [
    "### Combine the models together and calculate score\n",
    "\n",
    "In this step, the individual classifier scores are combined to obtain the overall multiclass classification score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ImageLoader(defect_class=None, do_train=False)\n",
    "filename_df = img.get(n=1000)\n",
    "filename_df = DefectViewer(row_chop=15, col_chop=15).get(filename_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e78f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.models import VectorClassifier\n",
    "vc = VectorClassifier(model_objects=model_objects, model_classes=model_classes, \n",
    "                      model_data_handlers=model_data_handlers, defect_classes=img.defect_classes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb1d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vc.test(filename_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in results.items():\n",
    "    print(f'{key}, {value[0]}, {value[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708cf4d1",
   "metadata": {},
   "source": [
    "##  Vs All Other Defects\n",
    "\n",
    "Now we run the classifier whereby the classification is set up to distinguish a single defect class vs all other possible defect classes, includeing the no defect present class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "complimentary = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49dfab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty objects for storing scores\n",
    "model_objects = []\n",
    "model_classes = []\n",
    "model_data_handlers = []\n",
    "\n",
    "# For each defect class, create the DataSet\n",
    "for cnt, defect_classes in enumerate(model_defect_classes):\n",
    "    if len(model_objects) >= cnt + 1:\n",
    "        continue\n",
    "        \n",
    "    print(f'Working on {defect_classes}')\n",
    "    start = time.perf_counter()\n",
    "    model_param = model_params[defect_classes]\n",
    "    \n",
    "    # Get the samples for the model\n",
    "    if isinstance(defect_classes, tuple):\n",
    "        classes = list(defect_classes)\n",
    "    else:\n",
    "        classes = defect_classes\n",
    "    \n",
    "    # Get the data for modeling\n",
    "    defect, not_defect = get_samples(classes, num_samples, complimentary=complimentary)\n",
    "    \n",
    "    # Get the data handler \n",
    "    data_handler = get_data_handler(defect_classes)\n",
    "    \n",
    "    # Get the pre processed data for this \n",
    "    defect_ = data_handler(defect, num_jobs=20)\n",
    "    not_defect_ = data_handler(not_defect, num_jobs=20)\n",
    "    print(not_defect_.category)\n",
    "    \n",
    "    # Show the pre and post processed images\n",
    "    # _ = Show(num_images=2, seed=seed) << (defect, defect_) + (not_defect, not_defect_)\n",
    "    \n",
    "    # Get the parameter for this classifier\n",
    "    this_param = copy.deepcopy(model_param)\n",
    "    model_class = this_param['class']\n",
    "    del this_param['class']\n",
    "    \n",
    "#     # Train the classifier \n",
    "#     print(defect_classes)\n",
    "#     cla = Classifier(defect_, not_defect_, model_class, None)\n",
    "#     score = cla.fit_cv(**this_param)\n",
    "    \n",
    "#     # Misclassified\n",
    "#     print(score)\n",
    "#     conf, out = cla.misclassified()\n",
    "#     print(tabulate.tabulate([['True 0', conf[0, 0], conf[0, 1]], ['True 1', conf[1, 0], conf[1, 1]]], headers=['', 'Pred 0', 'Pred 1']))\n",
    "    \n",
    "    # Train the classifier \n",
    "    cla = Classifier(defect_, not_defect_, model_class, None)\n",
    "    model = cla.fit(**this_param)\n",
    "    \n",
    "    model_objects.append(model)\n",
    "    model_classes.append(defect_classes)\n",
    "    model_data_handlers.append(data_handler)\n",
    "    \n",
    "    print(f'Completed {defect_classes} in {time.perf_counter()-start}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518620a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset to obtain the scoring information. \n",
    "img = ImageLoader(defect_class=None, do_train=False)\n",
    "filename_df = img.get(n=1000)\n",
    "filename_df = DefectViewer(row_chop=15, col_chop=15).get(filename_df)\n",
    "\n",
    "# Instantiate a new vector classifier class \n",
    "vc = VectorClassifier(model_objects=model_objects, model_classes=model_classes, \n",
    "                      model_data_handlers=model_data_handlers, defect_classes=img.defect_classes.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
